<!DOCTYPE html><html lang="en" mode="dark" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="theme" content="Chirpy v2.7.2"><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="Technologies Behind the Apple’s CSAM Detection System" /><meta name="author" content="Josip Rezić" /><meta property="og:locale" content="en_US" /><meta name="description" content="A few weeks ago Apple announced its new system that will scan iCloud for illegal child sexual abuse materials or CSAM. CSAM detection enables Apple to accurately identify and report iCloud users who store known CSAM material in their iCloud Photos accounts." /><meta property="og:description" content="A few weeks ago Apple announced its new system that will scan iCloud for illegal child sexual abuse materials or CSAM. CSAM detection enables Apple to accurately identify and report iCloud users who store known CSAM material in their iCloud Photos accounts." /><link rel="canonical" href="https://josiprezic.github.io/posts/technologies-behind-the-apples-csam-detection-system/" /><meta property="og:url" content="https://josiprezic.github.io/posts/technologies-behind-the-apples-csam-detection-system/" /><meta property="og:site_name" content="Josip Rezić" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-09-01T20:42:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Technologies Behind the Apple’s CSAM Detection System" /><meta name="twitter:site" content="@josip_rezic" /><meta name="twitter:creator" content="@Josip Rezić" /><meta name="google-site-verification" content="google09d0f5efd0a469ef.html" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"Josip Rezić"},"description":"A few weeks ago Apple announced its new system that will scan iCloud for illegal child sexual abuse materials or CSAM. CSAM detection enables Apple to accurately identify and report iCloud users who store known CSAM material in their iCloud Photos accounts.","url":"https://josiprezic.github.io/posts/technologies-behind-the-apples-csam-detection-system/","@type":"BlogPosting","headline":"Technologies Behind the Apple’s CSAM Detection System","dateModified":"2021-09-03T15:29:18+02:00","datePublished":"2021-09-01T20:42:00+02:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://josiprezic.github.io/posts/technologies-behind-the-apples-csam-detection-system/"},"@context":"https://schema.org"}</script><title>Technologies Behind the Apple’s CSAM Detection System | Josip Rezić</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="preload" href="/assets/css/post.css" as="style"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script async src="/assets/js/post.min.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Josip Rezić</a></div><div class="site-subtitle font-italic">There is an easy way and a hard way. The hard part is finding the easy way. ~ Dr. Lloyd</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/tabs/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tabs/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/tabs/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/tabs/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/josiprezic" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/josip_rezic" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['return.rezultat','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Technologies Behind the Apple’s CSAM Detection System</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Technologies Behind the Apple’s CSAM Detection System</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Sep 1, 2021, 8:42 PM +0200" > Sep 1 <i class="unloaded">2021-09-01T20:42:00+02:00</i> </span> by <span class="author"> Josip Rezić </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Fri, Sep 3, 2021, 3:29 PM +0200" > Sep 3 <i class="unloaded">2021-09-03T15:29:18+02:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1481 words">8 min</span></div></div><div class="post-content"><p><strong>A few weeks ago Apple announced its new system that will scan iCloud for illegal child sexual abuse materials or CSAM. CSAM detection enables Apple to accurately identify and report iCloud users who store known CSAM material in their iCloud Photos accounts.</strong></p><h1 id="introduction">Introduction</h1><p>Apple wants to help protect children from people who use communication tools to recruit and exploit them, and limit the spread of CSAM files. On the other side, Apple’s plan has been particularly controversial and has prompted concerns about the system potentially being abused by governments as a form of mass surveillance.</p><p>But rather than analyzing the benefits and drawbacks of this new feature, I would like to say a few words about the cryptographic techniques and protocols used for this system implementation.</p><h1 id="csam-detection-process">CSAM Detection Process</h1><p>Before explaining these technologies, let’s step back for a moment and take a quick look at the whole process of CSAM detection and its steps to get some more context around this.</p><p>So the steps are as follows:</p><ol><li><p><strong>Image upload initialization:</strong> When iCloud Photos is turned on, photos and videos stored on iPhones are automatically uploaded to iCloud. Once a new image appears in the Photos library, it will initiate the iCloud upload process.</p><li><p><strong>CSAM check triggered:</strong> The CSAM scanning system is a part of the iCloud Photos upload process and it will be triggered once the upload is initiated. Keep in mind that it does not scan private photo libraries stored on iPhone devices and it does not work for users who have iCloud Photos disabled.</p><li><p><strong>Hash calculation:</strong> Before uploading, the <strong>NeuralHash</strong> function is used to calculate hash values of these images.</p><li><p><strong>Hash comparison:</strong> The cryptographic technique called <strong>Private Set Intersection</strong>is used to match a database of image hashes provided by agencies like NCMEC to hashes calculated in the previous step to search for CSAM.</p><li><p><strong>iCloud upload:</strong> Hash comparison results created in the previous step are saved in the form of vouchers. These so-called safety vouchers are then uploaded to iCloud Photos along with the images.</p><li><p><strong>CSAM threshold exceeded:</strong> If the specified threshold (maximum number of images containing CSAM) is not exceeded, the cryptographic construction called <strong>Threshold Secret Sharing</strong> does not allow Apple servers to decrypt any match data, and does not permit Apple to count the number of matches for any given account. After the threshold is exceeded, Apple servers can decrypt vouchers corresponding to positive matches.</p><li><p><strong>Manual review process:</strong> This is further mitigated by a manual review process wherein Apple reviews each report to confirm there is a match, disables the user’s account, and sends a report to NCMEC.</p></ol><p>As we can see, the CSAM detection system combines three technologies:</p><ul><li><p>NeuralHash</p><li><p>Private Set Intersection</p><li><p>Threshold Secret Sharing</p></ul><h1 id="neuralhash">NeuralHash</h1><p>Apple defines NeuralHash as follows:</p><blockquote><p>NeuralHash is a perceptual hashing function that maps images to numbers. Perceptual hashing bases this number on features of the image instead of the precise values of pixels in the image. The system computes these hashes by using an embedding network to produce image descriptors and then converting those descriptors to integers using a Hyperplane LSH (Locality Sensitivity Hashing) process. This process ensures that different images produce different hashes.</p></blockquote><p><strong>NeuralHash</strong> technology analyzes an image and converts it to a hash (fixed-size string value) specific to that image content. Only another image that appears nearly identical can produce the same hash. The main purpose of the hash is to ensure that identical and visually similar images result in the same hash, and images that are different from one another result in different hashes.</p><p>Finally, it is worth mentioning that NeuralHash is not a machine learning classifier. It has not been trained on CSAM images and it does not contain extracted features from CSAM images (e.g. faces appearing in such images) or any ability to find such features elsewhere. Indeed, NeuralHash knows nothing at all about CSAM images. It is an algorithm designed to answer whether one image is really the same image as another, even if some image-altering transformations have been applied (like transcoding, resizing, and cropping). Below are a few examples used to highlight the general idea.</p><h1 id="private-set-intersection">Private Set Intersection</h1><p>Here is the definition from the Apple’s CSAM technical summary:</p><blockquote><p>Private Set Intersection (PSI) is a cryptographic protocol that two parties use, for example Apple servers and a user’s device. Before the protocol begins, Apple and the user’s device have distinct sets of image hashes that each system computed using the NeuralHash algorithm. […] The PSI protocol ensures that Apple learns the image hashes in the intersection of the two sets, but learns nothing about image hashes outside the intersection.</p></blockquote><p>Increasing dependence on anytime-anywhere availability of data and the commensurately increasing fear of losing privacy motivate the need for privacy-preserving techniques. One interesting and common problem occurs when two parties need to privately compute an intersection of their respective sets of data. In doing so, one or both parties must obtain the intersection (if one exists), while neither should learn anything about the other set.</p><p><strong>Private Set Intersection</strong> technique does exactly that. It allows two parties holding sets to compare encrypted versions of these sets in order to compute the intersection. In this scenario, neither party reveals anything to the other party except for the elements in the intersection.</p><p>Except for the CSAM detection, Apple uses this technique in Password Monitoring as well. Interestingly, this technique was also used during the COVID-19 pandemic to securely create digital contact tracing applications while keeping user privacy in mind.</p><p>The Apple’s system used for CSAM Detection extends this basic PSI mechanism to support the client including additional payload data associated with each image hash, and guarantees that this additional payload is only accessible for image hashes in the intersection of the two sets. Also, the system applies PSI in conjunction with other cryptographic techniques like Threshold Secret Sharing, described in the next section. To learn more about PSI, check the <a href="https://www.apple.com/child-safety/pdf/Apple_PSI_System_Security_Protocol_and_Analysis.pdf">Apple PSI system security protocol and analysis</a>.</p><h1 id="threshold-secret-sharing">Threshold Secret Sharing</h1><p>Wikipedia defines Secret Sharing as follows:</p><blockquote><p>Secret sharing refers to methods for distributing a secret among a group of participants, each of whom is allocated a share of the secret. The secret can be reconstructed only when a sufficient number, of possibly different types, of shares are combined; individual shares are of no use on their own.</p></blockquote><p>Suppose that we possess sensitive information (e.g. rocket launch codes, secret key for our shared crypto-wallet, sensitive database, etc.) and we want to protect it. Since we know that it is not a good idea to “put all eggs in one basket” and have a single point of failure, we have to look for some other, more advanced techniques used for information protection. We want to somehow split the secret and keep its pieces in a couple of different places. And that’s where the <strong>Threshold Secret Sharing</strong> comes in.</p><p><strong>Threshold Secret Sharing</strong> is a cryptographic technique that <strong>enables a secret to be split into distinct shares</strong> so it can only be reconstructed from a predefined number of shares (the threshold).</p><p>So let’s say that our rocket-launching secret is split into one thousand shares and the threshold is ten. Then the secret can be reconstructed from any ten of the one thousand shares. However, if only nine shares are available, then nothing is revealed about the secret.</p><h3 id="but-how-does-it-impact-the-csam-detection-system">But how does it impact the CSAM Detection system?</h3><p>The CSAM Detection system uses Threshold Secret Sharing to protect information about images stored in iCloud Photos when the number of matching images has not crossed a certain threshold. Only once the number of matches exceeds the threshold will the secret-sharing reconstruction algorithm enable the system to learn the additional data the client included with each of the matching images. Nothing is ever revealed about non-matching images during any step of the CSAM Detection process.</p><h1 id="conclusion">Conclusion</h1><p>CSAM Detection is a new feature that will be included in an upcoming release of iOS 15 and iPadOS 15. Instead of taking the same path for the CSAM detection as other big tech companies, Apple created their own, a little bit more privacy-oriented CSAM detection system.</p><p>Although this new system is under fire these days and it aroused a controversy among the iPhone users, I think we can all agree that the technologies used for the system implementation as well as their combination and interoperability are very interesting, or at least thought-provoking.</p><h1 id="sources">Sources</h1><ol><li><p><a href="https://www.apple.com/child-safety/">Expanded Protections for Children — Apple</a></p><li><p><a href="https://www.apple.com/child-safety/pdf/Expanded_Protections_for_Children_Technology_Summary.pdf">Expanded Protections for Children — Technology Summary</a></p><li><p><a href="https://www.apple.com/child-safety/pdf/Security_Threat_Model_Review_of_Apple_Child_Safety_Features.pdf">Security Threat Model Review of Apple’s Child Safety Features</a></p><li><p><a href="https://www.apple.com/105/media/us/child-safety/2021/7bc1183f-32b5-41da-8757-f7625cf634a3/films/usenix-security-symposium/child-safety-usenix-security-symposium-tpl-us-2021_16x9.m3u8">Presentation at USENIX Security Symposium by Ivan Krstic and Erik Neuenschwander</a></p><li><p><a href="https://www.apple.com/child-safety/pdf/CSAM_Detection_Technical_Summary.pdf">CSAM Detection — Technical Summary</a></p><li><p><a href="https://www.apple.com/child-safety/pdf/Apple_PSI_System_Security_Protocol_and_Analysis.pdf">Apple PSI System — Security Protocol and Analysis</a></p><li><p><a href="https://www.apple.com/child-safety/pdf/Technical_Assessment_of_CSAM_Detection_Benny_Pinkas.pdf">Technical Assessment of CSAM Detection — Benny Pinkas</a></p><li><p><a href="https://eprint.iacr.org/2009/491.pdf">Emiliano De Cristofaro and Gene Tsudik: Practical Private Set Intersection Protocols with Linear Computational and Bandwidth Complexity — University of California, Irvine</a></p><li><p><a href="http://cyber.biu.ac.il/wp-content/uploads/2020/02/Threshold-Secret-SharingToPublish.pdf">Gilad Asharov: Threshold Secret Sharing — Bar-Ilan University</a></p><li><p><a href="https://www.wikipedia.org/">wikipedia.org</a></p><li><p><a href="https://github.com/KhaosT/nhcalc">KhaosT/nhcalc</a></p><li><p><a href="https://github.com/AsuharietYgvar/AppleNeuralHash2ONNX">AsuharietYgvar/AppleNeuralHash2ONNX</a></p></ol></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/security/'>Security</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/apple/" class="post-tag no-text-decoration" >apple</a> <a href="/tags/neuralhash/" class="post-tag no-text-decoration" >neuralhash</a> <a href="/tags/private-set-intersection/" class="post-tag no-text-decoration" >private-set-intersection</a> <a href="/tags/threshold-secret-sharing/" class="post-tag no-text-decoration" >threshold-secret-sharing</a> <a href="/tags/privacy/" class="post-tag no-text-decoration" >privacy</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Technologies Behind the Apple’s CSAM Detection System - Josip Rezić&url=https://josiprezic.github.io/posts/technologies-behind-the-apples-csam-detection-system/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Technologies Behind the Apple’s CSAM Detection System - Josip Rezić&u=https://josiprezic.github.io/posts/technologies-behind-the-apples-csam-detection-system/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Technologies Behind the Apple’s CSAM Detection System - Josip Rezić&url=https://josiprezic.github.io/posts/technologies-behind-the-apples-csam-detection-system/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/technologies-behind-the-apples-csam-detection-system/">Technologies Behind the Apple’s CSAM Detection System</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/app-distribution/">app-distribution</a> <a class="post-tag" href="/tags/apple/">apple</a> <a class="post-tag" href="/tags/code-signing/">code-signing</a> <a class="post-tag" href="/tags/ios/">ios</a> <a class="post-tag" href="/tags/neuralhash/">neuralhash</a> <a class="post-tag" href="/tags/privacy/">privacy</a> <a class="post-tag" href="/tags/private-set-intersection/">private-set-intersection</a> <a class="post-tag" href="/tags/provisioning-profile/">provisioning-profile</a> <a class="post-tag" href="/tags/testflight/">testflight</a> <a class="post-tag" href="/tags/threshold-secret-sharing/">threshold-secret-sharing</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Provisioning_01/"><div class="card-body"> <span class="timeago small" > Jul 16 <i class="unloaded">2021-07-16T20:42:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>iOS Code Signing - Provisioning Profiles</h3><div class="text-muted small"><p> Probably every iOS developer has spent hours (maybe even days) checking and fixing the code signing setup, (re)creating required certificates, registering new testing devices etc. There is one com...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Provisioning_01/" class="btn btn-outline-primary"><p>iOS Code Signing - Provisioning Profiles</p></a> <span class="btn btn-outline-primary disabled"><p>-</p></span></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2021 <a href="https://twitter.com/josip_rezic">Josip Rezić</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy/" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/app-distribution/">app distribution</a> <a class="post-tag" href="/tags/apple/">apple</a> <a class="post-tag" href="/tags/code-signing/">code signing</a> <a class="post-tag" href="/tags/ios/">ios</a> <a class="post-tag" href="/tags/neuralhash/">neuralhash</a> <a class="post-tag" href="/tags/privacy/">privacy</a> <a class="post-tag" href="/tags/private-set-intersection/">private set intersection</a> <a class="post-tag" href="/tags/provisioning-profile/">provisioning profile</a> <a class="post-tag" href="/tags/testflight/">testflight</a> <a class="post-tag" href="/tags/threshold-secret-sharing/">threshold secret sharing</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://josiprezic.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
